# EX-02-Cross-Platform-Prompting-Evaluating-Diverse-Techniques-in-AI-Powered-Text-Summarization

## AIM
To evaluate and compare the effectiveness of prompting techniques (zero-shot, few-shot, chain-of-thought, role-based) across different AI platforms (e.g., ChatGPT, Gemini, Claude, Copilot) in a specific task: text summarization.

## SCENARIO:
You are part of a content curation team for an educational platform that delivers quick summaries of research papers to undergraduate students. Your task is to summarize a 500-word technical article on "The Basics of Blockchain Technology" using multiple AI platforms and prompting strategies.

Your goal is to determine which combination of prompting technique + platform provides the best summary in terms of:

Accuracy

Coherence

Simplicity

Speed

User experience

## OUTPUT
```
[ex-2.docx](https://github.com/user-attachments/files/24356383/ex-2.docx)

```
## RESULT
The experiment shows that few-shot and role-based prompting give the most accurate and coherent text summaries across all AI platforms. Chain-of-thought prompting improves logical flow but can make summaries slightly longer. Zero-shot prompting produces basic summaries with less consistency. Overall, ChatGPT and Claude perform best for text summarization, followed by Gemini, while Copilot works best with structured or few-shot prompts.
 
